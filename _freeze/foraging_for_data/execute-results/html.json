{
  "hash": "26864fa6c744859f383446e7ecffc467",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Foraging for Data in the Wild 2025\"\nauthor: \"Daniel Perez & Jori Kandra\"\n---\n\n\n\n\n\n## Welcome to the Foraging for Data in the Wild 2025 Landing page!\n\nThis training and code workflow was originally delivered as an EARN Talk on August 26th, 2025.\n\n**NOTE:** Some users have experienced issues downloading the datasets with the R commands below. An updated script and webinar recording will be shared in October 2025.\n\n## Unemployment Insurance Claims by State\n\n### 1) Import libraries\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(data.table) # setnames(), map DOL data dictionary to the raw data\nlibrary(lubridate) # data helper functions to recast messy data as date type\nlibrary(openxlsx2) # mapping data and setting formatting for excel wb\n```\n:::\n\n\n\n\n\n### 2) Download raw data\n\nUI IC & CC (NSA) comes for [ETA 539](https://oui.doleta.gov/unemploy/csv/ar539.csv), which can be found on the [DOL ETA website](https://oui.doleta.gov/unemploy/DataDownloads.asp).\n\nUse the command-line utility function wget to trigger and direct the download of exportable online data. Wrap the statement in system() to direct execution to the terminal\n\n**NOTE:** Some users encounter a 403 error with these commands. If this happens, manually download the `ar539.csv` file and place it in your working directory.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# \"wget -N\" omits download if data has not been updated \"-P\" sets the file destination\"\nsystem(\"wget -N https://oui.doleta.gov/unemploy/csv/ar539.csv  -P data/\")\n```\n:::\n\n\n\n\n\n### 3) Wrangle data\n\nReplace raw variable names using a user-defined data dictionary (download it [here](https://github.com/Economic/earn_code_library/blob/main/data/eta539_var_names.csv)).\n\nThe data dictionary is a combination of the [DOL ETA 539 Data Map](https://oui.doleta.gov/dmstree/handbooks/402/402_4/4024c6/4024c6.pdf#ETA539) (found on [Data Downloads](https://oui.doleta.gov/unemploy/DataDownloads.asp) page) and the [ETA 401 handook](https://www.dol.gov/sites/dolgov/files/ETA/handbooks/2017/ETHand401_5th.pdf) \"Item by Item Instructions.\"\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# read in data dictionary\ndata_dictionary <- read.csv(\"data/eta539_var_names.csv\")\n```\n:::\n\n\n\n\n\n### 4) Cleanse and manipulate data\n\nUse `data.table::setnames()` to apply the data dictionary to the raw data. Recast date columns to be of `Date` class type (or data storage type). \"Wild data\" often stores dates as `str` (or string) class type, so use functions from the `?lubridate` package to easily handle and manipulate date types.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Cleanse raw data\nraw_data <- read.csv(\"data/ar539.csv\") |>\n  # use $ operator to select column from data frame\n  setnames(old = data_dictionary$dol_code, new = data_dictionary$dol_title) |>\n  # format date as class 'Date' \n  mutate(report_date = mdy(report_date),\n         reflect_week_ending = mdy(reflect_week_ending))\n```\n:::\n\n\n\n\n\n### 5) Analyze\n\nUse `dplyr::mutate()` to create new columns. Calculate non-seasonally adjusted initial claims as state UI initial claims + short-term compensation (or workshare) initial claims and non-seasonally adjusted continued claims as state UI continued claims + short-tern compensation (or workshare) continued claims.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Initial claims (NSA) \ninitial_claims <- raw_data  |> \n  # Initial Claims & Continued Claims, non seasonally adjusted (as seen here: https://oui.doleta.gov/unemploy/claims.asp) \n  # UI IC is calculated from c3 (initial claims) & c7 (short time compensation workshare)\n  mutate(nsa_initial_claims = state_ui_initial_claims + stc_workshare_equivalent_initial_claims) |> \n  select(state, report_date, nsa_initial_claims) |> \n  # filter out unstable reporting\n  filter(report_date >= '1987-01-01') |>\n  # transform into wide format - each state is own column\n  #note: https://bookdown.org/Maxine/r4ds/pivoting.html\n  pivot_wider(id_cols = report_date, names_from = state, values_from = nsa_initial_claims) |> \n  # remove Puerto Rico and US Virgin Islands\n  select(-PR, -VI) |> \n  # replace state abbreviation with state name\n  setnames(old = state.abb, new = state.name) |> \n  # rename DC (not included in state* utility functions)\n  rename(`District of Columbia` = DC) |> \n  # sort data\n  arrange(report_date)\n\n# Continued claims (NSA) \ncontinued_claims <- raw_data |> \n  # Initial Claims & Continued Claims, non seasonally adjusted (as seen here: https://oui.doleta.gov/unemploy/claims.asp) \n  # UI CC is calculated from c8 & c12\n  mutate(nsa_continued_claims = state_ui_adjusted_continued_weeks_claimed + stc_workshare_equivalent_continued_weeks_claimed) |> \n  select(state, reflect_week_ending, nsa_continued_claims) |> \n  # filter out unstable reporting\n  filter(reflect_week_ending >= '1987-01-01') |>\n  # transform into wide format - each state is own column\n  pivot_wider(id_cols = reflect_week_ending, names_from = state, values_from = nsa_continued_claims) |> \n  # remove Puerto Rico & US Virgin Islands\n  select(-PR, -VI) |> \n  # replace state abbreviation with state name\n  setnames(old = state.abb, new = state.name) |> \n  # replace DC (not included in state.* utility data)\n  rename(`District of Columbia` = DC) |> \n  # sort data \n  arrange(reflect_week_ending)\n```\n:::\n\n\n\n\n\n### 6) Export data\n\nUse `?openxlsx2` to create excel workbooks, which support multiple tabs and backend formatting. This is a great way to generate replicable final products. Note that openxlsx2 uses the `$` pipe operator to modify workbook objects created by `openxlsx2::wb_workbook()`. Create worksheets, add data, and use functions such as `opnexlsx2::wb_set_col_widths()` and `openxlsx2::add_cell_style()` to stylize the workbook.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# create WB object\nwb <- wb_workbook()\n\n# write UI state IC to WB object\n#note: $ - pipe operator in openxlsx2 \nwb$\n  # add new worksheet\n  add_worksheet(sheet = \"Initial claims\")$\n  # add data to worksheet\n  add_data(x = initial_claims)$\n  # set columm widths\n  set_col_widths(cols = 2:ncol(initial_claims), widths = 15)$\n  # format column headers\n  add_cell_style(dims = wb_dims(rows = 1, cols = 2:ncol(initial_claims)), \n                 wrap_text = TRUE, horizontal = \"center\", vertical = \"center\")$\n  # repeat for continued claims\n  add_worksheet(sheet = \"Continued claims\")$\n  add_data(x = continued_claims)$\n  set_col_widths(cols = 2:ncol(continued_claims), widths = 15)$\n  add_cell_style(dims = wb_dims(rows = 1, cols = 2:ncol(continued_claims)), \n                 wrap_text = TRUE, horizontal = \"center\", vertical = \"center\")$\n  # save workbook to output folder\n  save(\"output/state_ui.xlsx\")\n```\n:::\n\n\n\n\n\n## Using the QCEW to measure employment growth in data centers by state\n\n> **Objectives**\n>\n> 1.  Create data by iteratively calling a function.\n> 2.  Bind/append data frames to create a large dataset.\n> 3.  Read data from a .CSV directly from the web into R.\n> 4.  Harmonize data types.\n> 5.  Use joins to combine datasets.\n> 6.  Filter using string detection.\n> 7.  Reorder variables using `select()`, `arrange()`, and/or `relocate()` functions.\n> 8.  Use some tricks to create quarterly and monthly data types with `lubridate`.\n> 9.  Measure employment changes for NAICS industry **518**.\n> 10. Bonus: quick visualization with **ggplot2**!\n\n**Question.** How has ‚Äúdata center‚Äù employment (NAICS 518) grown since late 2022, and in which states has it grown the most?\n\nTo answer these questions, we‚Äôll fetch 2022‚Äì2024 quarterly data for NAICS **518: Computing infrastructure providers, data processing, web hosting, and related services**.\n\n\\*\\* Disclaimer\\*\\*: I'm not sure if this is the most appropriate NAICS code, but it makes for a good exercise! Depending on your research question, you may want to refine how you select industry codes (e.g., include selected sub‚Äëindustries or complementary sectors.).\n\n## 1) Load libraries\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(lubridate)\n```\n:::\n\n\n\n\n\n## 2) BLS functions for loading QCEW data\n\nThe BLS conveniently provides a script and three functions for R users to load QCEW data directly into R! Below are two helpers adapted for this module. They construct an API URL and return a data frame for the requested year/quarter/industry or area.\n\nThese resources can be downloaded from this page: <https://www.bls.gov/cew/additional-resources/open-data/sample-code.htm#RSCRIPT>\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# This function loads all industries for one geographical area\nqcewGetAreaData <- function(year, qtr, area) {\n  url <- \"http://data.bls.gov/cew/data/api/YEAR/QTR/area/AREA.csv\"\n  url <- sub(\"YEAR\", year, url, ignore.case=FALSE)\n  url <- sub(\"QTR\", tolower(qtr), url, ignore.case=FALSE)\n  url <- sub(\"AREA\", toupper(area), url, ignore.case=FALSE)\n  read.csv(url, header = TRUE, sep = \",\", quote=\"\\\"\", dec=\".\", na.strings=\" \", skip=0)\n}\n\n# This function loads one industry for all geographical areas\nqcewGetIndustryData <- function (year, qtr, industry) {\n\turl <- \"http://data.bls.gov/cew/data/api/YEAR/QTR/industry/INDUSTRY.csv\"\n\turl <- sub(\"YEAR\", year, url, ignore.case=FALSE)\n\turl <- sub(\"QTR\", tolower(qtr), url, ignore.case=FALSE)\n\turl <- sub(\"INDUSTRY\", industry, url, ignore.case=FALSE)\n\tread.csv(url, header = TRUE, sep = \",\", quote=\"\\\"\", dec=\".\", na.strings=\" \", skip=0)\n}\n\n# Quick examples (not evaluated by default)\n# In ex. 1, we call the qcewGetAreaData() function, passing parameters for year, quarter, and areafips/geography i.e. year = 2015, quarter = 1, areafips = 26000 or Michigan.\n# We then assign the data called to a variable called MichiganData!\n\n#  MichiganData <- qcewGetAreaData(\"2015\", \"1\", \"26000\")\n#  Construction <- qcewGetIndustryData(\"2015\", \"1\", \"1012\")\n```\n:::\n\n\n\n\n\n## 3) QCEW data pull\n\nSince the example functions load only one quarter at a time, we'll want to make some modifications. Instead of calling the function 12 times by hand, we‚Äôll build a grid of parameters and map across it.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set our parameters \nyears <- 2022:2024\nquarters <- 1:4\nindustries <- c('518')   \n\n# create 12 combinations (3 years √ó 4 quarters √ó 1 industry) to pass through pmap()\ncombos <- tidyr::crossing(year = years, qtr = quarters, industry = industries)\n\n# Takes the combinations, runs qcewGetIndustryData() once for each\n# returns a list of \"small\" dataframes, which we combine into a large one called QCEW raw\n\nqcew_raw <- pmap(combos, function(year, qtr, industry){\n  qcewGetIndustryData(year, qtr, industry)\n  }) |> \n  # Combines all dataframes by appending/binding \"rows\" \n  bind_rows()\n\n# Explores our data\nglimpse(qcew_raw)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 29,108\nColumns: 42\n$ area_fips                       <chr> \"01000\", \"01000\", \"01001\", \"01003\", \"0‚Ä¶\n$ own_code                        <int> 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,‚Ä¶\n$ industry_code                   <int> 518, 518, 518, 518, 518, 518, 518, 518‚Ä¶\n$ agglvl_code                     <int> 55, 55, 75, 75, 75, 75, 75, 75, 75, 75‚Ä¶\n$ size_code                       <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,‚Ä¶\n$ year                            <int> 2022, 2022, 2022, 2022, 2022, 2022, 20‚Ä¶\n$ qtr                             <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,‚Ä¶\n$ disclosure_code                 <chr> \"\", \"\", \"N\", \"\", \"N\", \"\", \"N\", \"N\", \"N‚Ä¶\n$ qtrly_estabs                    <int> 1, 1019, 2, 31, 1, 4, 2, 1, 1, 0, 1, 6‚Ä¶\n$ month1_emplvl                   <int> 13, 2421, 0, 72, 0, 7, 0, 0, 0, 0, 0, ‚Ä¶\n$ month2_emplvl                   <int> 13, 2511, 0, 73, 0, 7, 0, 0, 0, 0, 0, ‚Ä¶\n$ month3_emplvl                   <int> 13, 2523, 0, 79, 0, 7, 0, 0, 0, 0, 0, ‚Ä¶\n$ total_qtrly_wages               <dbl> 249734, 60137580, 0, 1271327, 0, 67735‚Ä¶\n$ taxable_qtrly_wages             <dbl> 0, 20180327, 0, 574492, 0, 47119, 0, 0‚Ä¶\n$ qtrly_contributions             <int> 0, 322219, 0, 8174, 0, 2132, 0, 0, 0, ‚Ä¶\n$ avg_wkly_wage                   <int> 1478, 1862, 0, 1310, 0, 744, 0, 0, 0, ‚Ä¶\n$ lq_disclosure_code              <chr> \"\", \"\", \"N\", \"\", \"N\", \"\", \"N\", \"N\", \"N‚Ä¶\n$ lq_qtrly_estabs                 <dbl> 4.05, 1.81, 0.51, 1.06, 0.29, 0.39, 0.‚Ä¶\n$ lq_month1_emplvl                <dbl> 1.07, 0.40, 0.00, 0.31, 0.00, 0.05, 0.‚Ä¶\n$ lq_month2_emplvl                <dbl> 1.06, 0.42, 0.00, 0.31, 0.00, 0.05, 0.‚Ä¶\n$ lq_month3_emplvl                <dbl> 1.05, 0.42, 0.00, 0.33, 0.00, 0.05, 0.‚Ä¶\n$ lq_total_qtrly_wages            <dbl> 1.29, 0.30, 0.00, 0.21, 0.00, 0.02, 0.‚Ä¶\n$ lq_taxable_qtrly_wages          <dbl> 0.00, 0.33, 0.00, 0.25, 0.00, 0.04, 0.‚Ä¶\n$ lq_qtrly_contributions          <dbl> 0.00, 0.40, 0.00, 0.27, 0.00, 0.15, 0.‚Ä¶\n$ lq_avg_wkly_wage                <dbl> 1.21, 0.73, 0.00, 0.65, 0.00, 0.36, 0.‚Ä¶\n$ oty_disclosure_code             <chr> \"N\", \"\", \"N\", \"\", \"N\", \"\", \"N\", \"N\", \"‚Ä¶\n$ oty_qtrly_estabs_chg            <int> 0, 318, 0, 10, 1, 0, 1, -1, 1, 0, 0, 1‚Ä¶\n$ oty_qtrly_estabs_pct_chg        <dbl> 0.0, 45.4, 0.0, 47.6, 100.0, 0.0, 100.‚Ä¶\n$ oty_month1_emplvl_chg           <int> 0, 149, 0, 0, 0, 3, 0, 0, 0, 0, 0, -1,‚Ä¶\n$ oty_month1_emplvl_pct_chg       <dbl> 0.0, 6.6, 0.0, 0.0, 0.0, 75.0, 0.0, 0.‚Ä¶\n$ oty_month2_emplvl_chg           <int> 0, 216, 0, 0, 0, 2, 0, 0, 0, 0, 0, -1,‚Ä¶\n$ oty_month2_emplvl_pct_chg       <dbl> 0.0, 9.4, 0.0, 0.0, 0.0, 40.0, 0.0, 0.‚Ä¶\n$ oty_month3_emplvl_chg           <int> 0, 201, 0, 3, 0, 2, 0, 0, 0, 0, 0, -1,‚Ä¶\n$ oty_month3_emplvl_pct_chg       <dbl> 0.0, 8.7, 0.0, 3.9, 0.0, 40.0, 0.0, 0.‚Ä¶\n$ oty_total_qtrly_wages_chg       <dbl> 0, 13354348, 0, 210886, 0, 5327, 0, 0,‚Ä¶\n$ oty_total_qtrly_wages_pct_chg   <dbl> 0.0, 28.5, 0.0, 19.9, 0.0, 8.5, 0.0, 0‚Ä¶\n$ oty_taxable_qtrly_wages_chg     <int> 0, 2694560, 0, 39716, 0, 12909, 0, 0, ‚Ä¶\n$ oty_taxable_qtrly_wages_pct_chg <dbl> 0.0, 15.4, 0.0, 7.4, 0.0, 37.7, 0.0, 0‚Ä¶\n$ oty_qtrly_contributions_chg     <int> 0, -46111, 0, -4990, 0, 371, 0, 0, 0, ‚Ä¶\n$ oty_qtrly_contributions_pct_chg <dbl> 0.0, -12.5, 0.0, -37.9, 0.0, 21.1, 0.0‚Ä¶\n$ oty_avg_wkly_wage_chg           <int> 0, 295, 0, 203, 0, -285, 0, 0, 0, 0, 0‚Ä¶\n$ oty_avg_wkly_wage_pct_chg       <dbl> 0.0, 18.8, 0.0, 18.3, 0.0, -27.7, 0.0,‚Ä¶\n```\n\n\n:::\n:::\n\n\n\n\n\n## 4) Add readable labels (industry & area titles)\n\nOur dataframe is loaded! But it's not very legible. For starters, some geographic and industry titles would help.\n\nThe BLS provides a codebook for parsing our data <https://www.bls.gov/cew/about-data/downloadable-file-layouts/quarterly/naics-based-quarterly-layout.htm>. We'll load these directly into R.\n\n\\*\\* disclaimer \\*\\* depending on your IT's security settings, you may not be able to directly download these links into R. If you encounter this issue (like I did), you can navigate directly to the .htm links below, download the .CSV files, and place them in your working directory.\n\nIndustry titles downloaded from <https://www.bls.gov/cew/classifications/industry/industry-titles.htm>\n\nArea titles downloaded from <https://www.bls.gov/cew/classifications/areas/qcew-area-titles.htm>\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# link to csv files on the BLS QCEW site\nind_title_url <- 'https://www.bls.gov/cew/classifications/industry/industry-titles.csv'\narea_title_url <- 'https://www.bls.gov/cew/classifications/areas/area-titles-csv.csv'\n\n# # Read csv files directly into R from the QCEW page\n# ind_titles  <- read_csv(ind_title_url)\n# area_titles <- read_csv(area_title_url)\n\nind_titles <- read_csv('data/industry_titles.csv')\narea_titles <- read_csv('data/area-titles-csv.csv')\n```\n:::\n\n\n\n\n\n### 4a) First attempt at joining labels\n\nWe‚Äôll first attempt a natural `left_join()` on industry_code. A left join keeps all rows from our main dataset (qcew, the \"x\" table) and adds matches from ind_titles (the \"y\" table). By default, it matches on any identically named columns (a \"natural join\"), but we could also set the key explicitly using the `by =` argument.\n\nSee Section [19.4 How do joins work?](https://r4ds.hadley.nz/joins.html#how-do-joins-work) from [**R for Data Science (2e)**](https://r4ds.hadley.nz/) for some great visualizations.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Can you spot the difference?\nglimpse(qcew_raw$industry_code)   # likely <int> / <dbl>\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n int [1:29108] 518 518 518 518 518 518 518 518 518 518 ...\n```\n\n\n:::\n\n```{.r .cell-code}\nglimpse(ind_titles$industry_code) # likely <chr>\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n chr [1:2678] \"10\" \"101\" \"1011\" \"1012\" \"1013\" \"102\" \"1021\" \"1022\" \"1023\" ...\n```\n\n\n:::\n\n```{.r .cell-code}\n# What happens?\nqcew_raw |>\n  dplyr::left_join(ind_titles)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nJoining with `by = join_by(industry_code)`\n```\n\n\n:::\n\n::: {.cell-output .cell-output-error}\n\n```\nError in `dplyr::left_join()`:\n! Can't join `x$industry_code` with `y$industry_code` due to\n  incompatible types.\n‚Ñπ `x$industry_code` is a <integer>.\n‚Ñπ `y$industry_code` is a <character>.\n```\n\n\n:::\n:::\n\n\n\n\n\n### 4b) Harmonizing data types to join\n\nMaldito! We have an issue. Despite matching variable names, industry_code in datasets \"x\" and \"y\" are different datatypes. in \"x\", it's an integer, a numeric type. in \"y\" it's a character. In order to merge we need our datatypes to be the same.\n\nFortunately, is an easy fix. We can convert one of two columns to match data types. Which should we convert? Well, it's easier to go from character to numeric here. A quirk of R is that numerics don't have leading zeros, but strings can. You wouldn't write 100 as 0100, or 00100, right? Right??\n\nSince NAICS 3‚Äëdigit codes like 518 don‚Äôt have leading zeros, converting ind_titles\\$industry_code to numeric is safe here. (General tip: if codes are required to have leading zeros, keep them as character in both tables.)\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Make the join keys the same type\nind_titles <- ind_titles |>\n  mutate(industry_code = as.numeric(industry_code))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: There was 1 warning in `mutate()`.\n‚Ñπ In argument: `industry_code = as.numeric(industry_code)`.\nCaused by warning:\n! NAs introduced by coercion\n```\n\n\n:::\n\n```{.r .cell-code}\n# Now the join works:\nqcew_ind_clean <- qcew_raw |>\n  # natural join on identical names\n  left_join(ind_titles)  \n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nJoining with `by = join_by(industry_code)`\n```\n\n\n:::\n\n```{.r .cell-code}\n# We could also be explicit about which variable to join by\n# qcew_ind_clean <- qcew_raw |> \n#   left_join(ind_titles, by = 'industry_code')\n\n# If our variable names differ, we could map them using \n# left_join(ind_titles, by = c(\"industry_code\" = \"ind_code\"))\n```\n:::\n\n\n\n\n\n### 4c) Cleaning continued\n\nNow join titles and keep only variables we need. We also want limit to **private‚Äësector, statewide** data only. We know from the QCEW codebook that: `own_code == 5` and `agglvl_code == 55`.\n\nSee this codebook for more detail: [QCEW Field Layouts for NAICS-Based, Quarterly CSV Files](https://www.bls.gov/cew/about-data/downloadable-file-layouts/quarterly/naics-based-quarterly-layout.htm)\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# (If needed) ensure area_fips types match before joining area_titles\n# area_titles <- area_titles |> mutate(area_fips = as.character(area_fips))\n\nqcew_clean <- qcew_ind_clean |>\n  left_join(area_titles) |> \n  # Too many variables we don't need, let's restrict and re-order using select\n  select(\n    year, qtr, area_fips, area_title, industry_code,\n    industry_title, own_code, agglvl_code, month1_emplvl, month2_emplvl,\n    month3_emplvl) |> \n\n  # Now, why are seeing two rows for each state? Again, per the codebook, QCEW contains data for public and private sector industries\n  # We can filter for private sector data using own_code == 5\n  filter(own_code == 5) |> \n  filter(agglvl_code == 55)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nJoining with `by = join_by(area_fips)`\n```\n\n\n:::\n\n```{.r .cell-code}\n# Tip: An alternative way to filter for statewide data. If you don‚Äôt have a variable like agglvl_code, you can use string detection to filter statewide rows. We prefer to use code‚Äëbook filters when available.\n# filter(str_detect(area_title, \" -- Statewide\")) \n```\n:::\n\n\n\n\n\n## 5) Quarterly dates & averages\n\nCreate a quarterly average employment measure and a proper quarterly date using **lubridate**‚Äôs `yq()`.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nqcew_qtr <- qcew_clean |>\n  mutate(\n    qtr_avg_emp = (month1_emplvl + month2_emplvl + month3_emplvl) / 3,\n    qdate       = yq(paste(year, qtr, sep = \" Q\"))\n  )\n```\n:::\n\n\n\n\n\n## 6) Reshape to create state‚Äëby‚Äëcolumn tables\n\nNow that we have quarterly data, we'll use pivot_wider() to create a table of quarterly data that is long by date.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstate_qtr_table <- qcew_qtr |>\n  mutate(state = str_replace(area_title, \" -- Statewide\", \"\")) |>\n  select(qdate, state, qtr_avg_emp) |>\n  pivot_wider(id_cols = qdate, names_from = state, values_from = qtr_avg_emp)\n\nstate_qtr_table\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 12 √ó 54\n   qdate      Alabama Alaska Arizona Arkansas California Colorado Connecticut\n   <date>       <dbl>  <dbl>   <dbl>    <dbl>      <dbl>    <dbl>       <dbl>\n 1 2022-01-01   2485    96.3  12099.    4383.     66262.   16167.       3649.\n 2 2022-04-01   2772.  108    12538.    4546.     71640.   16592        3759.\n 3 2022-07-01   3060.  112.   12322     4705.     72875    16611.       3883.\n 4 2022-10-01   3143    97.3  12230     4746.     74211    16504        3795.\n 5 2023-01-01   3563.  117.   12441     4786.     84623    16157        3795 \n 6 2023-04-01   3699.  132.   12235.    4589      83776.   15891.       3778 \n 7 2023-07-01   3872   131.   11652.    4521.     83244.   15563        3750.\n 8 2023-10-01   3875   121    11905.    4494.     81299    15325.       3755.\n 9 2024-01-01   3738   108.   11401     4328      79753.   15234.       4081.\n10 2024-04-01   3812.  110.   11726.    4184.     79390.   15184        4314.\n11 2024-07-01   3929   130.   11374.    4170.     79600    15082.       4371 \n12 2024-10-01   3941   119.   11179.    4136.     78681.   14996.       4311.\n# ‚Ñπ 46 more variables: Delaware <dbl>,\n#   `District of Columbia, not unknown` <dbl>, Florida <dbl>, Georgia <dbl>,\n#   Hawaii <dbl>, Idaho <dbl>, Illinois <dbl>, Indiana <dbl>, Iowa <dbl>,\n#   Kansas <dbl>, Kentucky <dbl>, Louisiana <dbl>, Maine <dbl>, Maryland <dbl>,\n#   Massachusetts <dbl>, Michigan <dbl>, Minnesota <dbl>, Mississippi <dbl>,\n#   Missouri <dbl>, Montana <dbl>, Nebraska <dbl>, Nevada <dbl>,\n#   `New Hampshire` <dbl>, `New Jersey` <dbl>, `New Mexico` <dbl>, ‚Ä¶\n```\n\n\n:::\n:::\n\n\n\n\n\n## 7) Monthly data from QCEW\n\nThe QCEW provides monthly employment levels in each quarter! With a few tweaks to our data frame, we can produce a monthly series, giving us a more granular look at how data center employment has grown since 2022. Each QCEW quarter reports employment for its three months. We can unpivot those columns to build a monthly time series.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nqcew_monthly <- qcew_clean |>\n  pivot_longer(\n    cols = starts_with(\"month\"),\n    names_to = \"month_in_qtr\",\n    names_pattern = \"month(\\\\d+)_emplvl\",\n    values_to = \"emplvl\"\n  ) |>\n  mutate(\n    month_in_qtr = as.integer(month_in_qtr),\n    month        = (qtr - 1) * 3 + month_in_qtr,\n    date         = make_date(year, month, 1),\n  ) |>\n  select(area_title, area_fips, industry_code, year, qtr, date, emplvl) |>\n  arrange(area_title, year, qtr, date) |> \n  # let's clean up our state names!\n  mutate(state = str_replace(area_title, \" -- Statewide\", \"\"))\n\nhead(qcew_monthly)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 √ó 8\n  area_title         area_fips industry_code  year   qtr date       emplvl state\n  <chr>              <chr>             <dbl> <int> <int> <date>      <int> <chr>\n1 Alabama -- Statew‚Ä¶ 01000               518  2022     1 2022-01-01   2421 Alab‚Ä¶\n2 Alabama -- Statew‚Ä¶ 01000               518  2022     1 2022-02-01   2511 Alab‚Ä¶\n3 Alabama -- Statew‚Ä¶ 01000               518  2022     1 2022-03-01   2523 Alab‚Ä¶\n4 Alabama -- Statew‚Ä¶ 01000               518  2022     2 2022-04-01   2722 Alab‚Ä¶\n5 Alabama -- Statew‚Ä¶ 01000               518  2022     2 2022-05-01   2795 Alab‚Ä¶\n6 Alabama -- Statew‚Ä¶ 01000               518  2022     2 2022-06-01   2798 Alab‚Ä¶\n```\n\n\n:::\n:::\n\n\n\n\n\n## 8) Measure employment growth since late 2022\n\nFor a simple comparison, compute percentage change from **November 2022** to the latest available month for each state. (If a state is missing November specifically, we‚Äôll use the first available month on or after 2022‚Äë11‚Äë01.)\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstate_growth <- qcew_monthly |>\n  summarize(\n    start_emplvl = first(emplvl),\n    end_emplvl   = last(emplvl),\n    start_date   = first(date),\n    end_date     = last(date),\n    .by=state) |>\n  mutate(\n    emp_change = (end_emplvl - start_emplvl),\n    pct_change = (end_emplvl / start_emplvl - 1) * 100) |>\n  # arrange data in descending order by pct_change\n  arrange(desc(pct_change))\n\nstate_growth |> slice_head(n = 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 √ó 7\n   state     start_emplvl end_emplvl start_date end_date   emp_change pct_change\n   <chr>            <int>      <int> <date>     <date>          <int>      <dbl>\n 1 Alabama           2421       3929 2022-01-01 2024-12-01       1508       62.3\n 2 Idaho              903       1296 2022-01-01 2024-12-01        393       43.5\n 3 South Da‚Ä¶          293        405 2022-01-01 2024-12-01        112       38.2\n 4 Alaska              89        120 2022-01-01 2024-12-01         31       34.8\n 5 Wyoming            163        217 2022-01-01 2024-12-01         54       33.1\n 6 New Jers‚Ä¶        12474      16072 2022-01-01 2024-12-01       3598       28.8\n 7 Maryland          4377       5631 2022-01-01 2024-12-01       1254       28.6\n 8 Rhode Is‚Ä¶          625        787 2022-01-01 2024-12-01        162       25.9\n 9 New Hamp‚Ä¶         1465       1822 2022-01-01 2024-12-01        357       24.4\n10 West Vir‚Ä¶         1182       1439 2022-01-01 2024-12-01        257       21.7\n```\n\n\n:::\n:::\n\n\n\n\n\n## 9) Bonus: Making a quick visualization\n\nLets plot a few states using ggplot2\n\nP.S. check out [viz_workshop.qmd](viz_workshop.qmd) for some more ggplot examples!\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsel_state_data <- qcew_monthly |> \n  filter(state %in% c('Texas', 'Arkansas', 'Louisiana'))\n\nggplot(data = sel_state_data, aes(x=date, y=emplvl, color=state)) +\n  geom_line() +\n  labs(\n    title = \"Monthly employment (NAICS 518)\",\n    x = NULL, y = \"Employment level\",\n    color = \"State\"\n  ) \n```\n\n::: {.cell-output-display}\n![](foraging_for_data_files/figure-html/ggplots-1.png){width=672}\n:::\n:::\n\n\n\n\n\n## 10) Notes on reproducibility\n\n> Pro-tips: - This module reads files directly from **bls.gov**; those URLs occasionally change. If a link breaks, visit the QCEW classifications pages to refresh the URLs. - Consult **QCEW layout/codebook** to confirm variable meanings & aggregation levels for your projects.\n\nHappy coding!üï∫",
    "supporting": [
      "foraging_for_data_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}